# backend/app/services/workflow.py

from typing import TypedDict, List
import os
from pydantic import BaseModel, Field
from langchain_google_genai import GoogleGenerativeAI
# from langchain.chains import LLMChain  <- ä¸å†ä½¿ç”¨è¢«å¼ƒç”¨çš„LLMChain
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import PydanticOutputParser, StrOutputParser
from langgraph.graph import StateGraph, END
from .transcription import transcribe_audio_file

# --- 1. State å’Œ Pydantic æ¨¡åž‹ ---
class WorkflowState(TypedDict):
    audio_path: str
    transcript: str
    summary: str
    action_items: List[str]
    error: str
    google_api_key: str

class ActionItems(BaseModel):
    items: List[str] = Field(description="A list of action items from the meeting.")

# --- 2. èŠ‚ç‚¹å®šä¹‰ ---
def node_transcribe(state: WorkflowState):
    print("--- Node: Transcribing Audio ---")
    try:
        text = transcribe_audio_file(state["audio_path"])
        return {"transcript": text, "error": None}
    except Exception as e:
        error_message = f"Transcription failed: {e}"
        print(f"ðŸ”´ {error_message}")
        # å¤±è´¥æ—¶åªè¿”å›žé”™è¯¯ä¿¡æ¯ï¼Œä¸å†è¿”å›žç©ºçš„transcript
        return {"error": error_message}

def node_summarize(state: WorkflowState):
    print("--- Node: Summarizing Transcript ---")
    api_key = state["google_api_key"]
    
    # ä½¿ç”¨LCELæž„å»ºé“¾
    prompt = PromptTemplate.from_template(
        "Please provide a concise summary of the following meeting transcript:\n\n{transcript}"
    )
    llm = GoogleGenerativeAI(model="gemini-2.5-flash", temperature=0.4, google_api_key=api_key)
    # StrOutputParserç¡®ä¿æˆ‘ä»¬å¾—åˆ°çš„æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²
    chain = prompt | llm | StrOutputParser()
    
    summary = chain.invoke({"transcript": state["transcript"]})
    return {"summary": summary}

def node_extract_action_items(state: WorkflowState):
    print("--- Node: Extracting Action Items ---")
    api_key = state["google_api_key"]

    # ä½¿ç”¨LCELæž„å»ºé“¾ï¼Œå¹¶é‡‡çº³Copilotçš„å¥å£®æ€§æ£€æŸ¥æ€æƒ³
    parser = PydanticOutputParser(pydantic_object=ActionItems)
    prompt = PromptTemplate(
        template="Extract all action items from the meeting transcript.\n{format_instructions}\n\n{transcript}",
        input_variables=["transcript"],
        partial_variables={"format_instructions": parser.get_format_instructions()},
    )
    llm = GoogleGenerativeAI(model="gemini-1.5-flash", temperature=0, google_api_key=api_key)
    chain = prompt | llm | parser

    try:
        action_items_obj = chain.invoke({"transcript": state["transcript"]})
        items = action_items_obj.items if isinstance(action_items_obj, ActionItems) else []
        return {"action_items": items}
    except Exception as e:
        # å¦‚æžœPydanticè§£æžå¤±è´¥ï¼Œæˆ‘ä»¬ä¹Ÿä¼˜é›…åœ°å¤„ç†
        print(f"âš ï¸ Action items parsing failed: {e}")
        return {"action_items": []}

# --- 3. å†³ç­–å‡½æ•° ---
def decide_after_transcription(state: WorkflowState):
    print("--- Node: Deciding next step ---")
    if state.get("error"):
        print("-> Transcription failed. Ending workflow.")
        return "end_with_failure"
    else:
        print("-> Transcription succeeded. Continuing to summary.")
        return "continue_to_summary"

# --- 4. æž„å»ºå›¾ (Graph) ---
def build_graph():
    workflow = StateGraph(WorkflowState)
    workflow.add_node("transcribe", node_transcribe)
    workflow.add_node("summarize", node_summarize)
    workflow.add_node("extract_action_items", node_extract_action_items)
    workflow.set_entry_point("transcribe")
    workflow.add_conditional_edges(
        "transcribe",
        decide_after_transcription,
        {
            "continue_to_summary": "summarize",
            "end_with_failure": END,
        },
    )
    workflow.add_edge("summarize", "extract_action_items")
    workflow.add_edge("extract_action_items", END)
    return workflow.compile()

langgraph_app = build_graph()