from typing import TypedDict, List
import os
from pydantic import BaseModel, Field
from langchain_google_genai import GoogleGenerativeAI
from langchain.chains import LLMChain
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import PydanticOutputParser
from langgraph.graph import StateGraph, END
from .transcription import transcribe_audio_file

class WorkflowState(TypedDict):
    audio_path: str
    transcript: str
    summary: str
    action_items: List[str]
    error: str
    google_api_key: str

class ActionItems(BaseModel):
    items: List[str] = Field(description="A list of action items from the meeting.")

# --- èŠ‚ç‚¹å®šä¹‰ ---
def node_transcribe(state: WorkflowState):
    print("--- Node: Transcribing Audio ---")
    try:
        text = transcribe_audio_file(state["audio_path"])
        # ã€ä¿®æ­£ã€‘è¿”å›è½¬å½•ç»“æœçš„åŒæ—¶ï¼Œä¹Ÿæ¸…ç©ºerrorå­—æ®µ
        return {"transcript": text, "error": None}
    except Exception as e:
        error_message = f"Transcription failed: {e}"
        print(f"ğŸ”´ {error_message}")
        # ã€ä¿®æ­£ã€‘å½“å¤±è´¥æ—¶ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯
        return {"error": error_message}

# ... node_summarize å’Œ node_extract_action_items ä¿æŒä¸å˜ ...
def node_summarize(state: WorkflowState):
    print("--- Node: Summarizing Transcript ---")
    api_key = state["google_api_key"]
    llm = GoogleGenerativeAI(model="gemini-1.5-flash", temperature=0, google_api_key=api_key)
    prompt = PromptTemplate.from_template("Please provide a concise summary of the following meeting transcript:\n\n{transcript}")
    chain = LLMChain(llm=llm, prompt=prompt)
    summary = chain.invoke({"transcript": state["transcript"]})
    return {"summary": summary['text']}

def node_extract_action_items(state: WorkflowState):
    print("--- Node: Extracting Action Items ---")
    api_key = state["google_api_key"]
    llm = GoogleGenerativeAI(model="gemini-1.5-flash", temperature=0, google_api_key=api_key)
    parser = PydanticOutputParser(pydantic_object=ActionItems)
    prompt = PromptTemplate(
        template="Extract all action items from the meeting transcript. {format_instructions}\n\n{transcript}",
        input_variables=["transcript"],
        partial_variables={"format_instructions": parser.get_format_instructions()},
    )
    chain = prompt | llm | parser
    action_items_obj = chain.invoke({"transcript": state["transcript"]})
    return {"action_items": action_items_obj.items}


# --- ã€æ ¸å¿ƒä¿®æ­£ã€‘å†³ç­–èŠ‚ç‚¹ ---
def decide_after_transcription(state: WorkflowState):
    """å†³ç­–èŠ‚ç‚¹ï¼šåœ¨è½¬å½•åï¼Œæ ¹æ®æ˜¯å¦å­˜åœ¨é”™è¯¯æ¥å†³å®šä¸‹ä¸€æ­¥èµ°å‘ã€‚"""
    print("--- Node: Deciding next step ---")
    if state.get("error"):
        print("-> Transcription failed. Ending workflow.")
        return "end_with_failure"
    else:
        print("-> Transcription succeeded. Continuing to summary.")
        return "continue_to_summary"

# --- æ„å»ºå›¾ (Graph) ---
def build_graph():
    workflow = StateGraph(WorkflowState)
    workflow.add_node("transcribe", node_transcribe)
    workflow.add_node("summarize", node_summarize)
    workflow.add_node("extract_action_items", node_extract_action_items)

    # ã€æ ¸å¿ƒä¿®æ­£ã€‘æ·»åŠ å†³ç­–èŠ‚ç‚¹
    workflow.add_node("transcription_decision", decide_after_transcription)

    # ã€æ ¸å¿ƒä¿®æ­£ã€‘å®šä¹‰æ–°çš„æµç¨‹é€»è¾‘
    workflow.set_entry_point("transcribe")
    workflow.add_edge("transcribe", "transcription_decision")
    
    # æ·»åŠ æ¡ä»¶è¾¹
    workflow.add_conditional_edges(
        "transcription_decision",
        decide_after_transcription,
        {
            "continue_to_summary": "summarize",
            "end_with_failure": END,
        },
    )
    workflow.add_edge("summarize", "extract_action_items")
    workflow.add_edge("extract_action_items", END)
    
    return workflow.compile()

langgraph_app = build_graph()